---
title: "projet_neur"
output: html_document
date: "2025-02-10"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyr)
library(dplyr)
library(corrplot)
library(FactoMineR)
library(factoextra)
library(signal)       
library(plotly)

```

```{r}
data=read.csv("enr_1_modif.csv")
```



```{r}
#Aperçu des données
head(data)

#Description
summary(data)
```
```{r}
ggplot(data, aes(x = data[, 1])) +  # Colonne de temps sur l'axe x
  geom_line(aes(y = data[, 2], color = "Electrode 1")) +  # 2ème colonne (Electrode 1)
  geom_line(aes(y = data[, 3], color = "Electrode 2")) +  # 3ème colonne (Electrode 2)
  labs(x = "Temps", y = "Amplitude", title = "Signaux des électrodes")
```

```{r}
# Boxplot pour l'Electrode 1 (2e colonne du dataset)
boxplot(data[, 16], main = "Boxplot de l'Electrode 14", 
        ylab = "Amplitude", outline = TRUE)
# Boxplot pour les électrodes 1 à 20
boxplot(data[, 2:60], main = "Boxplots des Electrodes 1 à 59", 
        ylab = "Amplitude", col = rainbow(10), outline = FALSE, las = 2)


```

```{r}
# Transformer les données en format long
data_long <- data %>% pivot_longer(cols = -1, names_to = "Electrode", values_to = "Amplitude")

# Échantillonnage pour ggplot2 (1%)
sample_data_long <- data_long %>% sample_frac(0.01)

# Boxplot avec ggplot2
ggplot(sample_data_long, aes(x = Electrode, y = Amplitude)) +
  geom_boxplot(fill = "lightblue", outlier.colour = "red", outlier.size = 1) +
  labs(x = "Electrodes", y = "Amplitude", title = "Boxplots des Electrodes (échantillon 1%)") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

```{r}
# Moyenne et écart-type pour chaque électrode (excluant la colonne Temps)
mean_values <- colMeans(data[, -1], na.rm = TRUE)  # Moyenne
sd_values <- apply(data[, -1], 2, sd, na.rm = TRUE)  # Écart-type

# Affichage des premières valeurs
print("Moyennes pour les premières électrodes")
head(mean_values)
print("Ecarts-types pour les premières électrodes")
head(sd_values)


```
```{r}
# Matrice de corrélation
cor_matrix <- cor(data[, -1], use = "pairwise.complete.obs")

# Afficher un extrait de la matrice (les premières électrodes)
#head(cor_matrix[, 1:5])

#Matrice complète
#cor_matrix

#Matrice complète avec les ellipses
corrplot(cor_matrix, method = "ellipse", type = "full", tl.pos="n")

#Seulement la moitié supérieure pour plus de clarté
corrplot(cor_matrix, method = "ellipse", type = "upper", tl.pos = "n")



```
## ACP sur le signal brute


```{r}
# On applique l'ACP en ayant nos données centrées et réduites (scale.unit=TRUE)
pca_result <- PCA(data[, -1], scale.unit = TRUE, graph = FALSE)

#Résumé des résultats:
summary(pca_result, ncp=5) #5 composantes principales nécessaires

# Graphe des variances expliquées
fviz_screeplot(pca_result, addlabels = TRUE, barfill = "blue", barcolor = "black")

```
Commentaire : Ici, on a besoin de 5 (4 c'est ok, même 3 avec le graphe on remarque que c'est ok) dimensions pour expliquer 80% de notre jeu de données.

```{r}
# Cercle des corrélations
fviz_pca_var(pca_result, col.var = "contrib", repel = TRUE,label="none")
```
```{r}
#Je vais refaire mon cercle de corrélations en masquant tous les électrodes à nouveau sauf le 18, 19, 20 et 21 en créant mon propre label

# Filtrer les électrodes 18 à 22 (indices 18 à 22 dans le jeu de données)
electrodes_selected <- 19:23

# Extraire les coordonnées des électrodes sélectionnées pour les utiliser dans le cercle de corrélation
coord_selected <- pca_result$var$coord[electrodes_selected, ]

# Créer un graphique avec uniquement les électrodes 18 à 22
pca_plot_filtered <- fviz_pca_var(pca_result, 
                                  col.var = "contrib",    # Couleur selon la contribution des variables
                                  repel = TRUE,            # Empêcher le chevauchement des labels
                                  label = "none")          # Pas de labels par défaut

# Ajouter les flèches pour les électrodes sélectionnées
pca_plot_filtered + 
  geom_text(data = data.frame(x = coord_selected[, 1], y = coord_selected[, 2], 
                              label = rownames(coord_selected)), 
            aes(x = x, y = y, label = label), 
            color = "red", size = 3, fontface = "bold")
  

```
```{r}
# Projection des observations (points)
fviz_pca_ind(pca_result, label = "none", habillage = "none", geom = "point")
```
Commentaires : On ne remarque pas de tandances particulières. Pas de outliers particuliers.

```{r}
# Contribution des électrodes à PC1 et PC2
fviz_contrib(pca_result, choice = "var", axes = 1, top = 10)
fviz_contrib(pca_result, choice = "var", axes = 2, top = 10)

```
```{r}
#Réduction de la dimensionnalité : 

# Effectuer l'ACP et garder les 4 premières composantes principales
pca_result_4dim <- PCA(data[, -1], ncp = 4)

# Obtenir les scores des individus sur les 4 premières composantes principales
data_reduced_4dim <- pca_result_4dim$ind$coord

```
## Test clustering

```{r}
# Appliquer K-means sur les données réduites (4 dimensions)
set.seed(42)  # Pour la reproductibilité
kmeans_result <- kmeans(data_reduced_4dim, centers = 3)  # 3 clusters par exemple

# Visualiser les résultats
fviz_cluster(kmeans_result, data = data_reduced_4dim, geom = "point")

```
```{r}
kmeans_result$centers  # Afficher les centres des clusters
head(kmeans_result$cluster)  # Afficher l'assignation des clusters pour chaque individu

```










## Filtrage du signal
```{r}

sampling_rate <- 20000  # Fréquence d'échantillonnage (ex: 20 kHz, à adapter si différent)

# Création du filtre passe-bande
bf <- butter(4, c(300, 3000) / (sampling_rate / 2), type = "pass")  

# Appliquer le filtre à toutes les électrodes (sauf la colonne temps)
data_filtered <- data
data_filtered[, -1] <- apply(data[, -1], 2, function(x) filtfilt(bf, x))


```

Ici on met un filtre 300-3000 kHZ car :
-En dessous de 300 Hz : bruit de fond et variations lentes
-Au-dessus de 3000 Hz : artefacts et bruit haute fréquence


##Détection de pics

###Calcul du seuil

```{r}
#Pour l'instant, je définis le seuil comme 5 fois celui de l'écart type. J'en définis un positif et un négatif.
thresholds_pos <- apply(data_filtered[, -1], 2, function(x) mean(x) + 5 * sd(x))
thresholds_neg <- apply(data_filtered[, -1], 2, function(x) mean(x) - 5 * sd(x))
```

###Trouver les pics

```{r}
#Fonction pour détecter les pics positifs et négatifs
find_peaks <- function(signal, threshold_pos, threshold_neg) {
  peaks_pos <- which(signal > threshold_pos)  # Pics positifs, retourne les indices où le signal dépasse le seuil
  peaks_neg <- which(signal < threshold_neg)  # Pics négatifs
  return(list(pos = peaks_pos, neg = peaks_neg))
}
```


```{r}
#Appliquer la détection des pics à toutes les électrodes
spikes <- lapply(2:ncol(data_filtered), function(i) 
  find_peaks(data_filtered[, i], thresholds_pos[i-1], thresholds_neg[i-1])
)
names(spikes) <- colnames(data_filtered)[-1]  # Associer chaque électrode


```
lapply() applique find_peaks() à toutes les électrodes
spikes contient les indices de pics pour chaque électrode

###Visualisation des pics

```{r}
#Visualisation des pics sur une électrode
electrode_id <- 2  # Exemple : électrode 1 (colonne 2 du dataframe)
time <- data[, 1]  # Récupérer la colonne temps

ggplot() +
  geom_line(aes(x = time, y = data_filtered[, electrode_id]), color = "blue") +  # Signal filtré
  geom_point(aes(x = time[spikes[[electrode_id - 1]]$pos], 
                 y = data_filtered[spikes[[electrode_id - 1]]$pos, electrode_id]), 
             color = "red", size = 2) +  # Pics positifs
  geom_point(aes(x = time[spikes[[electrode_id - 1]]$neg], 
                 y = data_filtered[spikes[[electrode_id - 1]]$neg, electrode_id]), 
             color = "green", size = 2) +  # Pics négatifs
  labs(title = paste("Détection des pics sur l'électrode", colnames(data_filtered)[electrode_id]))

```

##Extraction des formes d'ondes des pics

```{r}
#On extrait 20 points avant et après chaque pics 

extract_waveforms <- function(signal, peaks, window = 20) {
  # Filtrer les pics trop proches des bords
  valid_peaks <- peaks[peaks > window & peaks < (length(signal) - window)]
  
  # Extraire les segments autour des pics valides
  waveforms <- lapply(valid_peaks, function(p) signal[(p - window):(p + window)])
  
  return(waveforms)
}

# Appliquer à toutes les électrodes
waveforms <- lapply(2:ncol(data_filtered), function(i) 
  extract_waveforms(data_filtered[, i], spikes[[i-1]]$pos)  # Pour les pics positifs uniquement
)

# Associer les noms des électrodes
names(waveforms) <- colnames(data_filtered)[-1]


```
Qu'est ce que j'ai dans les colonnes de ma matrice une fois les pics sélectionnés ? => Nombre de pics x Nombre de points par segment ? essayer de voir si je peux adapter le nbr de points que je prends avant et après en fonction de la taille du pic (mais le problème c'est que après on a une matrice avec des colonnes de tailles différentes)

Chaque pic est stocké sous forme de mini-signal de 40 points

On peut ensuite les visualiser pour voir leur morphologie

##Clustering des pics

###ACP sur les pics

Avant de faire l’ACP, on doit transformer les pics extraits en une matrice exploitable. Actuellement, waveforms est une liste où chaque entrée correspond aux segments extraits autour des pics pour chaque électrode.

Objectif : Convertir cette liste en une matrice où chaque ligne représente un pic et chaque colonne un point temporel autour du pic.

```{r}
# Transformer les segments en une matrice
waveform_matrix <- do.call(rbind, lapply(waveforms, function(electrode_waveforms) {
  do.call(rbind, electrode_waveforms)  # Chaque pic devient une ligne
}))

# Vérifier la taille de la matrice
dim(waveform_matrix)  # Nombre de pics x Nombre de points par segment

```
lapply(waveforms, ...) applique la fusion (rbind) sur chaque électrode.

do.call(rbind, ...) assemble tous les pics pour créer une matrice finale.


On applique maintenant l'ACP
```{r}
# Centrer-réduire les données avant ACP
waveform_matrix_scaled <- scale(waveform_matrix)

# Appliquer ACP avec prcomp()
pca_waveforms <- prcomp(waveform_matrix_scaled, center = TRUE, scale. = TRUE)

# Visualiser la variance expliquée
fviz_eig(pca_waveforms, addlabels = TRUE)

```
scale() centre et réduit les valeurs pour éviter les biais liés aux amplitudes.

prcomp() exécute l’ACP.

fviz_eig() permet de voir combien de dimensions sont nécessaires pour expliquer la variance.

```{r}
# Calcul de la variance cumulée
variance_expliquee <- summary(pca_waveforms)$importance[3, ]  # Ligne 3 = variance cumulée
#nb_cp_opt <- which(variance_expliquee >= 0.80)[1]  # 80% de variance
#print(nb_cp_opt)

#Sinon choisir à la main nb_opt_opt
nb_cp_opt=3

# Réduction des données avec ces composantes
waveform_pca_data <- pca_waveforms$x[, 1:nb_cp_opt]

```
Visualiser les individus
```{r}
#fviz_pca_ind(pca_waveforms, label = "none", habillage = "none", geom = "point") automatiquement il prend les dim 1 et 2
fviz_pca_ind(pca_waveforms, label = "none", habillage = "none", geom = "point",axes = c(1, 2))
fviz_pca_ind(pca_waveforms, label = "none", habillage = "none", geom = "point",axes = c(1, 3))
fviz_pca_ind(pca_waveforms, label = "none", habillage = "none", geom = "point",axes = c(2, 3))

```
Se poser les questions : qui sont les individus ect ...

```{r}
#Rajouter ici la visualisation 3D

```



Chaque point de l'ACP représenge un pic

###Clustering


Trouver le bon nombre de clusters pour K-means => méthode du coude et silhouette

####Méthode du coude 

```{r}
fviz_nbclust(waveform_pca_data, kmeans, method = "wss")  # Elbow method
```
Erreur car mon jeu de données est trop gros 
Je vais tester avec un sous échantillon de données pour la méthode du coude 

```{r}
set.seed(42)  # Pour reproductibilité
sample_indices <- sample(nrow(waveform_pca_data), size = 5000)  # Sélectionne 5000 points aléatoires
waveform_sample <- waveform_pca_data[sample_indices, ]

# Relancer la méthode Elbow
fviz_nbclust(waveform_sample, kmeans, method = "wss")

```
On a sélectionner 5000 points aléatoires car sinon il y avait trop de données. On obtient ainsi une estimation du nombre de clusters idéal sans calculer sur toute la base.

=> Nbr idéal : 2 clusters

####Méthode silhouette 

On peut vérifier avec la méthode silhouette

```{r}
library(cluster)

# Application du clustering k-means
sil_width <- sapply(2:10, function(k) {
  km <- kmeans(waveform_pca_data, centers = k, nstart = 10)
  mean(silhouette(km$cluster, dist(waveform_pca_data))[, 3])
})

# Visualisation de la largeur moyenne de silhouette pour chaque nombre de clusters
plot(2:10, sil_width, type = "b", pch = 19, frame = FALSE, 
     xlab = "Nombre de clusters", ylab = "Largeur moyenne de silhouette")

```
Pareil, problème de taille. Je fais le même procédé que pour la méthode du coude.

```{r}
set.seed(42)  # Pour assurer la reproductibilité
sample_size <- 5000  # Nombre d'échantillons à extraire

# Extraire un sous-échantillon aléatoire des données (5000 points)
sample_indices <- sample(1:nrow(waveform_pca_data), sample_size)
waveform_pca_data_sampled <- waveform_pca_data[sample_indices, ]


library(cluster)

# Calculer la silhouette sur un échantillon de 5000 points pour différentes valeurs de k
sil_width_sampled <- sapply(2:10, function(k) {
  km <- kmeans(waveform_pca_data_sampled, centers = k, nstart = 10)
  mean(silhouette(km$cluster, dist(waveform_pca_data_sampled))[, 3])
})

```

```{r}
# Trouver k optimal en cherchant le maximum de silhouette
optimal_k <- which.max(sil_width_sampled) + 1  # +1 car l'index commence à 2

#On limite le nbr max de clusters à 5
if (optimal_k > 5) { 
  optimal_k <- which.max(sil_width_sampled[1:4]) + 1  # Cherche le max parmi k=2 à k=5
}

# Plot de la largeur moyenne de silhouette pour chaque k
plot(2:10, sil_width_sampled, type = "b", pch = 19, frame = FALSE, 
     xlab = "Nombre de clusters", ylab = "Largeur moyenne de silhouette")

# Ajouter une ligne verticale pour marquer le nombre optimal de clusters
abline(v = optimal_k, col = "red", lty = 2)
text(optimal_k, sil_width_sampled[optimal_k - 1], labels = paste("k =", optimal_k), pos = 4, col = "red")

```
####On applique K-means

```{r}
#On regroupe les pics en cluster

set.seed(42)  # Reproductibilité
k_opt <- 5  # 2 clusters
kmeans_result <- kmeans(waveform_pca_data, centers = k_opt, nstart = 25)

# Ajouter les labels des clusters aux données
waveform_pca_data <- data.frame(waveform_pca_data, Cluster = as.factor(kmeans_result$cluster))


```

####Visualisation

```{r}
waveform_pca_data$Cluster <- as.numeric(as.character(waveform_pca_data$Cluster))
str(waveform_pca_data)  # Vérifie le type des données

```


```{r}
#fviz_cluster(kmeans_result, data = waveform_pca_data, geom = "point")

#Pour éviter toute confusion :

fviz_cluster(kmeans_result, data = waveform_pca_data[, 1:2], geom = "point")
#On lui passe seulement les 3 premières dimensions de l’ACP (PC1, PC2, PC3) pour bien utiliser les données réduites après ACP.



```
C'est plutot pas mal 

Faire attention à ce que fviz_cluster ne refasse pas une ACP ==> fviz_cluster() ne refait pas une ACP, mais par défaut, il n'affiche que les deux premières dimensions principales (PC1 et PC2), ce qui peut donner l'impression que l'ACP est refaite.
Explication en détail de ce que fais fviz_cluster : 

-Utilise les coordonnées de l’ACP (déjà calculées) pour afficher les clusters.
-Projette les points sur un plan 2D (en général PC1 et PC2).
-Ne refait PAS une ACP, mais affiche les clusters en réduisant la dimension à 2D pour la visualisation.

####Visualisation en 3D : 

```{r}
library(scatterplot3d)

scatterplot3d(waveform_pca_data$PC1, 
              waveform_pca_data$PC2, 
              waveform_pca_data$PC3, 
              color = as.numeric(waveform_pca_data$Cluster), 
              pch = 19, main = "Clustering en 3D (PC1, PC2, PC3)")

```


####Identifier les caractéristiques des clusters

A retravailler

```{r}
#library(reshape2)
#waveform_pca_data$Cluster <- kmeans_result$cluster

# Calcul de la moyenne des formes d'onde par cluster
#mean_waveforms <- aggregate(waveform_matrix, by = list(Cluster = waveform_pca_data$Cluster), mean)

# Visualisation
#ggplot(melt(mean_waveforms, id.vars = "Cluster"), aes(x = variable, y = value, color = as.factor(Cluster))) +
#  geom_line() +
#  labs(title = "Forme moyenne des pics par cluster")

```

